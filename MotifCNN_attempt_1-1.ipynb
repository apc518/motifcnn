{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K_HOlVLEGo_"
      },
      "source": [
        "### Load the Data\n",
        "\n",
        "upload a data set with file structure \n",
        "\n",
        "data/positive and data/negative\n",
        "\n",
        "then add empty data/spec/positive and\n",
        "data/spec/negative directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptTP1cKQScLe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if \"data\" in os.listdir():\n",
        "  os.system(\"rm -rf data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIpby2SIBxKn"
      },
      "outputs": [],
      "source": [
        "# Used to unzip a data set loaded to the drive\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"solo.zip\") as z:\n",
        "  z.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh1TBjWmbR_d"
      },
      "source": [
        "### Data Preprocessing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJezMoXi9Fmb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def convert_audio_to_spectogram(filename, outfilename=None, overwrite=False):\n",
        "    \"\"\"\n",
        "    convert_audio_to_spectogram -- using librosa to plot and save a spectrogram\n",
        "    \n",
        "    Arguments:\n",
        "    filename -- filepath to the file that you want to see the waveplot for\n",
        "    outfilename -- filepath to the output spectrogram (must be something matplotlib.pyplot.savefig() can handle)\n",
        "    overwrite -- whether to overwrite if a file already exists with the given outfilename\n",
        "    \n",
        "    Returns -- None\n",
        "    \"\"\"\n",
        "    \n",
        "    # sr == sampling rate \n",
        "    audio_data, sr = librosa.load(filename, sr=44100)\n",
        "\n",
        "    vertical_res = 4096\n",
        "    \n",
        "    # stft is short time fourier transform\n",
        "    sgram = librosa.stft(audio_data, center=False, n_fft=vertical_res, win_length=vertical_res)\n",
        "    \n",
        "    # convert the slices to amplitude\n",
        "    sgram_db = librosa.amplitude_to_db(abs(sgram))\n",
        "\n",
        "    _, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "    librosa.display.specshow(sgram_db, sr=sr, x_axis='time', y_axis='log', ax=ax, cmap='gray')\n",
        "\n",
        "    # plt.gca().set_axis_off()\n",
        "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0,\n",
        "                hspace = 0, wspace = 0)\n",
        "    plt.margins(0,0)\n",
        "\n",
        "    if outfilename in os.listdir() and not overwrite:\n",
        "        print(\"Given filename already exists, to overwrite pass in argument `overwrite=True`\")\n",
        "        return\n",
        "    if outfilename is not None:\n",
        "        plt.savefig(outfilename)\n",
        "\n",
        "        # crop the image to get rid of useless high and low frequencies\n",
        "        im = Image.open(outfilename)\n",
        "        im_cropped = im.crop((0, 90, 360, 315))\n",
        "        im_cropped.save(outfilename)\n",
        "    \n",
        "    plt.close() # dont display the spectrogram on screen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE_LHyuQ1M3A",
        "outputId": "e5d0c029-86b4-4906-d2be-733e13adcfa7"
      },
      "outputs": [],
      "source": [
        "for item in os.listdir(\"./solo/positives\"):\n",
        "    convert_audio_to_spectogram(\"./solo/positives/\"+item, f\"./spec/positives/{item.rsplit('.', 1)[0]}.png\")\n",
        "\n",
        "for item in os.listdir(\"./solo/negatives\"):\n",
        "    convert_audio_to_spectogram(f\"./solo/negatives/{item}\", f\"./spec/negatives/{item.rsplit('.', 1)[0]}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "449xgkbgyQLo",
        "outputId": "ba2820d9-bc4a-4c97-82d5-fdda256adf05"
      },
      "outputs": [],
      "source": [
        "import matplotlib.image as mpimg\n",
        "img = mpimg.imread('spec/positives/lick_0000.png')\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58b_CBegPXoe"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxOjlqu9yGNC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyh2MP5rPW1h",
        "outputId": "320262e9-b966-498f-f7cf-1cb0717fc91b"
      },
      "outputs": [],
      "source": [
        "# Load dataset from directory with keras\n",
        "\n",
        "# sometimes a directory called .ipynb_checkpoints is present, remove it if so\n",
        "if os.path.isdir('./data/.ipynb_checkpoints'):\n",
        "  os.removedirs(\"./data/.ipynb_checkpoints\")\n",
        "\n",
        "train_directory = './data/'\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_directory, labels='inferred', label_mode='int', image_size=(360,225), seed=123,\n",
        "    validation_split=0.2, subset='validation')\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "rNLI6LurQ5QD",
        "outputId": "6f7956e5-c9ac-4956-94f7-67036f7da435"
      },
      "outputs": [],
      "source": [
        "# Straight from the microsoft tutorial \n",
        "# shows the spectrograms with their labels\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(2):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 5, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g62tgPpVRnCZ"
      },
      "source": [
        "### Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HubMU1CCRqi0"
      },
      "outputs": [],
      "source": [
        "# This came from the tutorial\n",
        "\n",
        "\n",
        "# Define the model\n",
        "\n",
        "num_classes = 2\n",
        "img_height = 225\n",
        "img_width = 360\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_width, img_height, 3)),\n",
        "\n",
        "  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf2tADTqR1w4",
        "outputId": "6baf924f-be00-4842-90dc-28dd9f35a551"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "metrics = ['accuracy']\n",
        "model.compile(optimizer, loss_fn, metrics)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWpasDujR4z9",
        "outputId": "5699b40d-1e5f-4030-d1fa-95b2bf0a2d2b"
      },
      "outputs": [],
      "source": [
        "# Set the epochs\n",
        "epochs = 15\n",
        "print('\\nFitting:')\n",
        "\n",
        "# Train the model.\n",
        "history = model.fit(train_ds, epochs=epochs, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IQVJPvZAL5aj",
        "outputId": "b0bc3ea9-5f53-4dd8-fa5d-09c19ea76be6"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL4cnS0xlnKC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MotifCNN-attempt-1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
